# --- SETUP ---
!git clone https://github.com/HaggertyTristen/DataDemo.git
%cd DataDemo/Project

import os
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

# Paths
train_path = "train"
test_path = "test"

resize = (128,128)  # resize for display

def plot_variants(img, title):
    """Display RGB, grayscale, and channel variants in a single row of 8 images."""
    img = img.resize(resize).convert("RGB")
    arr = np.array(img)

    # --- RGB channels ---
    r = arr.copy(); r[:,:,1:] = 0     # red only
    g = arr.copy(); g[:,:,0]=0; g[:,:,2]=0   # green only
    b = arr.copy(); b[:,:,:2]=0      # blue only

    # --- Grayscale ---
    gray = np.array(img.convert("L"))
    gray_r = np.stack([gray, np.zeros_like(gray), np.zeros_like(gray)], axis=2)
    gray_g = np.stack([np.zeros_like(gray), gray, np.zeros_like(gray)], axis=2)
    gray_b = np.stack([np.zeros_like(gray), np.zeros_like(gray), gray], axis=2)

    # --- Collect all versions ---
    variants = [
        (arr, "RGB"),
        (np.array(img.convert("L")), "Gray"),
        (r, "Red"),
        (g, "Green"),
        (b, "Blue"),
        (gray_r, "Gray→Red"),
        (gray_g, "Gray→Green"),
        (gray_b, "Gray→Blue")
    ]

    # --- Plot grid (1 row, 8 columns) ---
    fig, axes = plt.subplots(1, 8, figsize=(24,4))
    for ax, (vimg, vtitle) in zip(axes, variants):
        if len(vimg.shape) == 2:  # grayscale
            ax.imshow(vimg, cmap="gray")
        else:
            ax.imshow(vimg)
        ax.set_title(vtitle, fontsize=10)
        ax.axis("off")
    fig.suptitle(title, fontsize=14)
    plt.show()

def display_all_images(root_folder):
    classes = os.listdir(root_folder)
    for cls in classes:
        class_folder = os.path.join(root_folder, cls)
        if not os.path.isdir(class_folder):
            continue
        print(f"\nShowing images for class: {cls}")
        images = os.listdir(class_folder)
        for fname in images:
            fpath = os.path.join(class_folder, fname)
            try:
                img = Image.open(fpath)
                plot_variants(img, f"{cls} - {fname}")
            except Exception as e:
                print(f"Could not open {fpath}: {e}")

# --- DISPLAY TRAIN IMAGES ---
print("Displaying TRAIN images...")
display_all_images(train_path)

# --- DISPLAY TEST IMAGES ---
print("\nDisplaying TEST images...")
display_all_images(test_path)






# ============================
# Recyclable vs Non-Recyclable Classification + Visualization
# ============================

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import cv2
import pandas as pd

# ============================
# 1. Dataset Setup
# ============================

data_dir = "/content/DataDemo/Project"  # adjust path if needed
train_dir = os.path.join(data_dir, "train")
test_dir = os.path.join(data_dir, "test")

transform = transforms.Compose([
    transforms.Resize((128,128)),
    transforms.ToTensor()
])

train_dataset = datasets.ImageFolder(train_dir, transform=transform)
test_dataset = datasets.ImageFolder(test_dir, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

classes = train_dataset.classes
print("Classes:", classes)

# ============================
# 2. Simple CNN Model
# ============================

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2,2)
        self.fc1 = nn.Linear(8*64*64, 2)
    def forward(self, x):
        x = F.relu(self.conv1(x))
        feat_map = x.clone()  # keep feature map
        x = self.pool(x)
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        return x, feat_map

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# ============================
# 3. Train Model (quick)
# ============================

for epoch in range(2):
    model.train()
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs, _ = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1}, Loss={loss.item():.4f}")

# ============================
# 4. Visualization Function
# ============================

def show_image_analysis(img, label, pred, probs, feat_map):
    img_np = img.permute(1,2,0).cpu().numpy()
    gray = cv2.cvtColor((img_np*255).astype(np.uint8), cv2.COLOR_RGB2GRAY)

    # Extract channels
    r, g, b = img_np[:,:,0], img_np[:,:,1], img_np[:,:,2]
    grey_r = cv2.merge([gray, np.zeros_like(gray), np.zeros_like(gray)])
    grey_g = cv2.merge([np.zeros_like(gray), gray, np.zeros_like(gray)])
    grey_b = cv2.merge([np.zeros_like(gray), np.zeros_like(gray), gray])

    # Plot row
    fig, axs = plt.subplots(1, 8, figsize=(24,3))
    variants = [img_np,
                np.stack([r*255, np.zeros_like(r), np.zeros_like(r)], axis=2),
                np.stack([np.zeros_like(g), g*255, np.zeros_like(g)], axis=2),
                np.stack([np.zeros_like(b), np.zeros_like(b), b*255], axis=2),
                cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB),
                grey_r, grey_g, grey_b]
    titles = ["RGB", "Red", "Green", "Blue", "Gray", "GrayR", "GrayG", "GrayB"]

    for ax, v, t in zip(axs, variants, titles):
        ax.imshow(v.astype(np.uint8))
        ax.set_title(t, fontsize=8)
        ax.axis("off")

    plt.suptitle(f"True: {classes[label]} | Pred: {classes[pred]}", fontsize=12, color="blue")
    plt.show()

    # Feature maps
    fmap = feat_map[0].detach().cpu().numpy()
    fig, axs = plt.subplots(1, min(5,fmap.shape[0]), figsize=(12,3))
    for i in range(min(5,fmap.shape[0])):
        axs[i].imshow(fmap[i], cmap="viridis")
        axs[i].axis("off")
    plt.suptitle("CNN Feature Maps")
    plt.show()

    # Probability bar plot
    plt.bar(classes, probs)
    plt.title("Prediction Confidence")
    plt.show()

    # Augmentations
    aug = transforms.RandomRotation(30)
    aug_img = aug(img).permute(1,2,0).numpy()
    plt.figure(figsize=(5,3))
    plt.imshow(aug_img)
    plt.title("Augmentation Preview")
    plt.axis("off")
    plt.show()

# ============================
# 5. Run on ALL Test Images
# ============================

model.eval()
with torch.no_grad():
    for imgs, labels in test_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        outputs, feat_map = model(imgs)
        probs = F.softmax(outputs, dim=1)
        preds = torch.argmax(probs, dim=1)
        for i in range(len(imgs)):
            show_image_analysis(imgs[i], labels[i].item(), preds[i].item(),
                                probs[i].cpu().numpy(), feat_map[i:i+1])

# ============================
# 6. Metadata Summary
# ============================

summary = {
    "Class": [],
    "Count": [],
    "Avg Red": [],
    "Avg Green": [],
    "Avg Blue": []
}
for c, path in train_dataset.class_to_idx.items():
    img_paths = [os.path.join(train_dir, c, f) for f in os.listdir(os.path.join(train_dir,c))]
    reds, greens, blues = [],[],[]
    for p in img_paths:
        img = cv2.imread(p)
        if img is None: continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        reds.append(np.mean(img[:,:,0]))
        greens.append(np.mean(img[:,:,1]))
        blues.append(np.mean(img[:,:,2]))
    summary["Class"].append(c)
    summary["Count"].append(len(img_paths))
    summary["Avg Red"].append(np.mean(reds))
    summary["Avg Green"].append(np.mean(greens))
    summary["Avg Blue"].append(np.mean(blues))

df = pd.DataFrame(summary)
print(df)

import os
import torch
from torchvision import transforms
from PIL import Image

# 1. Clone the GitHub repository
print("Cloning the repository...")
!git clone https://github.com/HaggertyTristen/DataDemo.git

# Define the root directory where the repository was cloned
repo_path = 'DataDemo/Project'

# Define the output directories for the processed images
output_rgb_dir = 'processed_rgb'
output_greyscale_dir = 'processed_greyscale'

# Create the output directories if they don't exist
os.makedirs(output_rgb_dir, exist_ok=True)
os.makedirs(output_greyscale_dir, exist_ok=True)

# Define PyTorch image transformations
# For RGB, we just need to convert the image to a tensor
transform_rgb = transforms.ToTensor()
# For Greyscale, we convert to grayscale and then to a tensor
transform_greyscale = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.ToTensor()
])

def process_images(image_dir, transform_type):
    """
    Processes all images in a given directory, applies a specified
    transformation, and saves the transformed image.
    """
    if transform_type == 'rgb':
        transform = transform_rgb
        output_dir = output_rgb_dir
        print("\nProcessing images to RGB...")
    elif transform_type == 'greyscale':
        transform = transform_greyscale
        output_dir = output_greyscale_dir
        print("\nProcessing images to Greyscale...")
    else:
        return

    # Walk through the directories to find all image files
    for root, _, files in os.walk(image_dir):
        for file in files:
            # Check for common image file extensions
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                input_path = os.path.join(root, file)

                try:
                    # Open the image using PIL
                    image = Image.open(input_path).convert('RGB')

                    # Apply the transformation
                    transformed_tensor = transform(image)

                    # For greyscale, convert back to a PIL image for saving
                    # (ToTensor converts to a tensor with values [0, 1])
                    if transform_type == 'greyscale':
                        pil_image = transforms.ToPILImage()(transformed_tensor)
                        pil_image.save(os.path.join(output_dir, file))
                    else: # For RGB, save the original-like image
                        pil_image = transforms.ToPILImage()(transformed_tensor)
                        pil_image.save(os.path.join(output_dir, file))

                    print(f"Processed and saved: {file} to {output_dir}")

                except Exception as e:
                    print(f"Error processing {file}: {e}")

# Process all images in the train and test folders
process_images(os.path.join(repo_path, 'train'), 'rgb')
process_images(os.path.join(repo_path, 'train'), 'greyscale')
process_images(os.path.join(repo_path, 'test'), 'rgb')
process_images(os.path.join(repo_path, 'test'), 'greyscale')

print("\nImage processing complete!")
